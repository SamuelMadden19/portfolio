{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST CNN With Keras\n",
    "#### Samuel Madden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.5 (default, Mar 30 2018, 06:41:53) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]\n",
      "Pandas Version: 0.22.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# Keras imports\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "# Ouptut System Versions\n",
    "print(\"Python Version: \" + sys.version)\n",
    "print(\"Pandas Version: \" + pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('mnist/mnist_train.csv')\n",
    "\n",
    "mnist_test = pd.read_csv('mnist/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6742\n",
       "7    6265\n",
       "3    6131\n",
       "2    5958\n",
       "9    5949\n",
       "0    5923\n",
       "6    5918\n",
       "8    5851\n",
       "4    5842\n",
       "5    5421\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X_train, Y_train = mnist_train.iloc[:,1:], mnist_train['label']\n",
    "\n",
    "X_test, Y_test = mnist_test.iloc[:, 1:], mnist_test['label']\n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All labels (0-9) are accounted for in the above value count with \n",
    "no unexpected Null or -1 instances.\n",
    "\n",
    "The labels between 0 - 9 are also relatively evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# note dimension of data images\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Scan for Null/Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a grayscale normalization\n",
    "\n",
    "Convert the pixel lumination from a value between 0 - 255 to a scale of 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data images are 28px X 28px. These images are reshaped to 2D representation of 1 x 784\n",
    "in the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>1x10</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...    28x19  28x20  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28, width = 28, chanal = 1)\n",
    "\n",
    "# check image shape\n",
    "#X_train[0].shape\n",
    "\n",
    "X_train = X_train.values.reshape(-1, img_rows, img_cols, 1)\n",
    "\n",
    "X_test = X_test.values.reshape(-1, img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "Keras requires a 3 dimensional input to correspond to height, width and channel.</br>\n",
    "In the case of MNIST, the images are grayscale and require one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info: \n",
      "Type:  <class 'numpy.ndarray'>\n",
      "Dimensions:  4\n",
      "Type var stored:  float64\n",
      "\n",
      "\n",
      "X_test info: \n",
      "Type:  <class 'numpy.ndarray'>\n",
      "Dimensions:  4\n",
      "Type var stored:  float64\n"
     ]
    }
   ],
   "source": [
    "# X_train\n",
    "print(\"X_train info: \")\n",
    "print(\"Type: \", type(X_train))\n",
    "print(\"Dimensions: \", X_train.ndim)\n",
    "print(\"Type var stored: \", X_train.dtype)\n",
    "print(\"\\n\")\n",
    "\n",
    "# X_test\n",
    "print(\"X_test info: \")\n",
    "print(\"Type: \", type(X_test))\n",
    "print(\"Dimensions: \", X_test.ndim)\n",
    "print(\"Type var stored: \", X_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are 10 single digits 0 - 9. </br>\n",
    "&#09;&bull; Convert each digit to a corresponding hot vector ex. 2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]. This allows for identification due to the corresponding activation of one of the 10 output neurons.</br>\n",
    "&bull; Again this transforms the data from type pandas.DataFrame to a np.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train info: \n",
      "Type:  <class 'numpy.ndarray'>\n",
      "Dimensions:  2\n",
      "Type var stored:  float32\n"
     ]
    }
   ],
   "source": [
    "# Y_train\n",
    "print(\"Y_train info: \")\n",
    "print(\"Type: \", type(Y_train))\n",
    "print(\"Dimensions: \", Y_train.ndim)\n",
    "print(\"Type var stored: \", Y_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Splitting Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and validation sets for fitting the model\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&bull; 10% is partitioned to the evaluation set while the remaining 90% is used to train the model. </br>\n",
    "&bull; A random split of the training data is admissable as we have already established that the distribution of labels is consistent across the data set (see 2.1). This ensures no overrepresentation of certain labels in the X_train/Y_train and X_val/Y_val.</br></br>\n",
    "&bull; This is not always the case and for unbalanced datasets use stratify = True option in train_test_split function (Only for >=0.17 sklearn versions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "Print a sample element of the X_train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Defining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras data model type will be set to 'Sequential', in which the model is built one layer at a time.</br>\n",
    "&nbsp; &bull; add() function will add layers to the model individually</br>\n",
    "&nbsp; &bull; The inputs of 32 & 64 refer to the number of nodes in specific layer</br>\n",
    "\n",
    "Conv2D layers are convolutional layers that deal with the 2 dimensional matrix input (a.k.a. input images). </br>\n",
    "This is a learnable filter that is a transformation on the image defined by the kernel size</br>\n",
    "&nbsp; &bull; Kernel size refers to the size of the filter matrix for the convolutional layer. Size=3 means a 3x3 conv matrix</br>\n",
    "&nbsp; &bull; Activation function is set to ReLU define by y=max(0,x), which lends to model sparsity and faster convergence.</br>\n",
    "&nbsp; &bull; MaxPool2D picks the max value of the neighboring pool\n",
    "\n",
    "The Flatten layer converts the final feature maps into a single 1D vector. </br>\n",
    "Dense refers to the fact that each neuron of a layer are connected to all the neurons of the layer previous.</br>\n",
    "Dropout randomly selects nodes to be ignored(set w=0), promoting distributed learning, generalization and reducing overfitting.\n",
    "\n",
    "The output layer consists of 10 nodes, representing the classification options of 0-9</br>\n",
    "&nbsp; &bull; 'softmax' has the output layer sum to 1 allowing the output nodes to be interpreted as probabilities of their corresponding number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN model\n",
    "\n",
    "# Architexture: Input -> [[Conv2D->ReLU]*2 -> MaxPool2D -> Dropout] * 2 -> \n",
    "#  Flatten -> Dense -> Dropout -> Output\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Compiling the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and settup a Score Function, Loss Function and Optimisation algorithm</br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
